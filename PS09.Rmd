---
title: "STAT/MATH 495: Problem Set 09"
author: "Wayne Maumbe"
date: "2017-11-07"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE
  )
set.seed(76)

library(tidyverse)
graph<-vector("list",10)
```



# Collaboration

Please indicate who you collaborated with on this assignment: 

Meron Gedrago

# Question 1: Run k-means

```{r}
observations_1 <- read_csv("data/observations_1.csv")
observations_2 <- read_csv("data/observations_2.csv")

# Set observations to be one of two datasets
observations <- observations_2

# Fit model for k=2
for (i in 1:10) {
  
k <- 2
k_means_results <- kmeans(observations, centers=k, iter.max = 10)
clusters <- k_means_results$cluster
cluster_centers <- k_means_results$centers




# Add cluster results to observations. Note we convert to factor since cluster
# ID's should be treated as categorical
observations$cluster <- as.factor(clusters)

# Add cluster ID's to cluster_centers
cluster_centers <- cluster_centers %>% 
  as_tibble() %>% 
  mutate(cluster=as.factor(1:k))

graph[[i]]<-ggplot(NULL, aes(x=x1, y=x2, col=cluster)) +
  geom_point(data=observations) +
  geom_point(data=cluster_centers, size=5)
}
gridExtra::grid.arrange(graph[[1]],graph[[2]],graph[[3]],graph[[4]],graph[[5]],graph[[6]],graph[[7]],graph[[8]],graph[[9]],graph[[10]],ncol=2)
```


```{r}
# Set observations to be one of two datasets
observations <- observations_1

for (i in 1:10) {
# Fit model for k=2
k <- 2
k_means_results <- kmeans(observations, centers=k, iter.max = 10)
clusters <- k_means_results$cluster
cluster_centers <- k_means_results$centers




# Add cluster results to observations. Note we convert to factor since cluster
# ID's should be treated as categorical
observations$cluster <- as.factor(clusters)

# Add cluster ID's to cluster_centers
cluster_centers <- cluster_centers %>% 
  as_tibble() %>% 
  mutate(cluster=as.factor(1:k))

graph[[i]]<-ggplot(NULL, aes(x=x1, y=x2, col=cluster)) +
  geom_point(data=observations) +
  geom_point(data=cluster_centers, size=5)

}
gridExtra::grid.arrange(graph[[1]],graph[[2]],graph[[3]],graph[[4]],graph[[5]],graph[[6]],graph[[7]],graph[[8]],graph[[9]],graph[[10]],ncol=2)


```

**Questions**:

1. Run KMC 10 times on `observations_1` and comment on the consistency of the
results.
alternating 
2. Speculate on the root cause of any consistency or inconsistency in the
results.
3. Run KMC 10 times on `observations_2` and comment on the consistentcy of the
results.
4. Speculate on the root cause of any consistency or inconsistency in the
results.

**Answers**:

####Observation 1
1. The resulting plots for KMC run 10 times show an alternating pattern between clusters that is the 1st and 2nd, 5th and 6th and 9th and 10th. They show that the assignment of points to either cluster 1 or 2 is alternating. 
  The separation/ clustering is consistent throughout the 10 times. This means that each cluster either 1 or 2 is always containing the same points regardless of which cluster it is. 
  
2. The inconsistency noted above is due to the random assignment of clusters 1 or 2 to the points. The separation/clustering is consistent because the algorithm aims to minimize dissimilarity within  the group and increase it between the group.

####Observation 2
3. The resulting plots for KMC run 10 times show after 7 times a somewhat alternating pattern between clusters. They show that thereafter the assignment of points to either cluster 1 or 2 is alternating.  
  The separation/ clustering is consistent throughout the 10 times. This means that each cluster either 1 or 2 is always containing the same points regardless of which cluster it is. 
  
4. The inconsistency noted above is due to the random assignment of clusters 1 or 2 to the points. The separation/clustering is consistent because the algorithm aims to minimize dissimilarity within  the group and increase it between the group. 




# Bonus question: Code your own

Read ISLR page 388 Algorithm 10.1 and implement k-means clustering from scratch.
Don't worry about doing it for general $k$; keep it simple and do it for $k=2$
specifically. Apply it to `observations_2` from above.

```{r eval=FALSE}
# Hint:
library(proxy)
A <- data_frame(
  x1 = c(0, 0.5, 0.75, 1),
  x2 = c(0, 0.5, 0.75, 1)
)
B <- data_frame(
  x1 = c(1, 0),
  x2 = c(1, 0)
)
distance_matrix <- proxy::dist(x=A, y=B)
distance_matrix
apply(distance_matrix, 1, which.min)
```
